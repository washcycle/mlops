{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KissSTfX_ffs"
   },
   "source": [
    "# How to track models end-to-end in Neptune\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/examples/blob/main/how-to-guides/e2e-tracking/notebooks/e2e_tracking.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/examples/blob/main/how-to-guides/e2e-tracking\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/table?viewId=9cb5bc7c-3bce-4c69-8f5c-90d3d9cc682c\">\n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://docs.neptune.ai/tutorials/e2e_tracking/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook shows how you can use Neptune to track a model across all stages of its lifecycle by\n",
    "* **Logging model and run metadata to a central project**\n",
    "* **Grouping models by their stage**\n",
    "* **Comparing models to select the best performing model**\n",
    "* **Monitoring a model once in production**\n",
    "\n",
    "You will learn how to use the Neptune webapp to explore run metadata, compare runs, and manually promote a model. However, this notebook can also be used as a template to design an automated end-to-end pipeline that covers the entire lifecycle of a model  without needing any manual intervention.\n",
    "\n",
    "This example uses Optuna hyperparameter-optimization to simulate training and evaluating multiple XGBoost models, and Evidently to monitor models in production. However, given Neptune's flexibility and [multiple integrations](https://docs.neptune.ai/integrations/), you can use any library and framework of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBuf35ln_ffu"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "This notebook example lets you try out Neptune anonymously, with zero setup.\n",
    "\n",
    "If you want to see the example logged to your own workspace instead:\n",
    "\n",
    "  1. Create a Neptune account. [Register &rarr;](https://neptune.ai/register)\n",
    "  1. Create a Neptune project that you will use for tracking metadata. For instructions, see [Creating a project](https://docs.neptune.ai/setup/creating_project) in the Neptune docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIyyFtiq_ffv"
   },
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VejAVKQW_ffv"
   },
   "outputs": [],
   "source": [
    "! pip install -qU \"neptune[xgboost,optuna]\" xgboost scikit-learn optuna evidently matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kg89LzXW_ffw"
   },
   "outputs": [],
   "source": [
    "# To fix the `RuntimeError: main thread is not in main loop` error in Windows\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend(\"agg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmVyyxci_ffw"
   },
   "source": [
    "## Track model training\n",
    "\n",
    "In this section, we'll use the following:\n",
    "- [Optuna](https://optuna.org/) to train multiple [XGBoost](https://xgboost.readthedocs.io/en/stable/) regression models,\n",
    "- Neptune's [XGBoost](https://docs.neptune.ai/integrations/xgboost/) and [Optuna](https://docs.neptune.ai/integrations/optuna/) integrations to automatically log metadata and metrics to Neptune for easy run visualization and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAE5s4h6_ffw"
   },
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4ZTD9VHG_ffx"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"valid\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5py0BvZ7_ffx"
   },
   "source": [
    "### Set up Neptune environment variables\n",
    "\n",
    "To connect to the Neptune app, you need to tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "You can use the default code cell below to create an anonymous run in the public project [common/e2e-tracking](https://app.neptune.ai/common/e2e-tracking). **Note**: Public projects are cleaned regularly, so anonymous runs are only stored temporarily.\n",
    "\n",
    "#### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"]=getpass(\"Enter your Neptune API token: \")\n",
    "os.environ[\"NEPTUNE_PROJECT\"]=\"workspace-name/project-name\",  # replace with your own\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bjXU7QRl_ffy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s4e11'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import neptune\n",
    "\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"] \n",
    "os.environ[\"NEPTUNE_PROJECT\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdBKB3hX_ffy"
   },
   "source": [
    "### Create the Optuna objective function\n",
    "We will create trial level runs within the objective function to capture trial-level metadata using Neptune's XGBoost integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zn6GNl7a_ffy",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    from neptune.integrations.xgboost import NeptuneCallback\n",
    "\n",
    "    # Define model parameters\n",
    "    model_params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 0, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 2, 9),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 0.75),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": [\"mae\", \"rmse\"],\n",
    "    }\n",
    "\n",
    "    # Define training parameters\n",
    "    train_params = {\n",
    "        \"num_boost_round\": trial.suggest_int(\"num_boost_round\", 10, 50),\n",
    "    }\n",
    "\n",
    "    # Create a trial-level run\n",
    "    run_trial_level = neptune.init_run(\n",
    "        capture_hardware_metrics=True,\n",
    "        capture_stderr=True,\n",
    "        capture_stdout=True,\n",
    "        capture_traceback=True,\n",
    "        tags=[\"notebook\", \"trial-level\", \"neptune\"],\n",
    "    )\n",
    "\n",
    "    # Log study name and trial number to trial-level run\n",
    "    run_trial_level[\"study-name\"] = str(study.study_name)\n",
    "    run_trial_level[\"trial-number\"] = trial.number\n",
    "\n",
    "    # Log training parameters of a trial-level run\n",
    "    run_trial_level[\"training/parameters\"] = train_params\n",
    "\n",
    "    # Model parameters are logged automatically by the NeptuneCallback\n",
    "\n",
    "    # Create NeptuneCallback to log trial-level metadata\n",
    "    neptune_xgb_callback = NeptuneCallback(run=run_trial_level)\n",
    "\n",
    "    # Train the model and log trial-level metadata to the trial-level run\n",
    "    model = xgb.train(\n",
    "        params=model_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=train_params[\"num_boost_round\"],\n",
    "        evals=evals,\n",
    "        verbose_eval=False,\n",
    "        callbacks=[\n",
    "            neptune_xgb_callback,\n",
    "            xgb.callback.LearningRateScheduler(lambda epoch: 0.99**epoch),\n",
    "            xgb.callback.EarlyStopping(rounds=10, save_best=True, maximize=False),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Use group tags to identify the stage of the model\n",
    "    run_trial_level[\"sys/group_tags\"].add([\"development\"])\n",
    "\n",
    "    # Stop trial-level run\n",
    "    run_trial_level.stop()\n",
    "\n",
    "    return model.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAEBI9E7_ffy"
   },
   "source": [
    "### Create the Optuna study and a Neptune study-level run\n",
    "This run will have all the study-level metadata from Optuna, and can be used to group and compare runs across multiple HPO sweeps/studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aUJQ9xL7_ffy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/mlops/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-11-20 20:02:16,158] A new study created in memory with name: no-name-9e4f005d-83d1-4261-b64c-e0f0d9152c9b\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jYZKHWGk_ffy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs.neptune.ai/help/nvml_error/\n"
     ]
    }
   ],
   "source": [
    "run_study_level = neptune.init_run(\n",
    "    capture_hardware_metrics=True,\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    "    capture_traceback=True,\n",
    "    tags=[\"notebook\", \"study-level\"],\n",
    "    dependencies=\"infer\",\n",
    ")\n",
    "\n",
    "run_study_level[\"study-name\"] = study.study_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph1Hdpzc_ffz"
   },
   "source": [
    "### Initialize Neptune's Optuna callback\n",
    "This will log the HPO sweeps and trials to the study-level run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yBh5xzpP_ffz"
   },
   "outputs": [],
   "source": [
    "from neptune.integrations.optuna import NeptuneCallback as NeptuneOptunaCallback\n",
    "\n",
    "neptune_optuna_callback = NeptuneOptunaCallback(run_study_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYDFMVBn_ffz"
   },
   "source": [
    "### Run the hyperparameter-sweep with Neptune's Optuna callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wWpxguWt_ffz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-9\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 307 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 307 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-9/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 20:03:37,590] Trial 0 finished with value: 0.5434750359790907 and parameters: {'max_depth': 3, 'min_child_weight': 2, 'learning_rate': 0.684532526940596, 'colsample_bytree': 0.5911815948889912, 'subsample': 0.9393969574202261, 'num_boost_round': 47}. Best is trial 0 with value: 0.5434750359790907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-11-20 20:03:37,945] Param learning_rate unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,949] Param max_depth unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,954] Param min_child_weight unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,959] Param num_boost_round unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,963] Param subsample unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,967] Param colsample_bytree unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,971] Param max_depth unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,975] Param min_child_weight unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,978] Param num_boost_round unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,982] Param subsample unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,986] Param colsample_bytree unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,989] Param learning_rate unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,992] Param min_child_weight unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:37,997] Param num_boost_round unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,002] Param subsample unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,005] Param colsample_bytree unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,010] Param learning_rate unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,013] Param max_depth unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,017] Param num_boost_round unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,021] Param subsample unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,025] Param colsample_bytree unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,028] Param learning_rate unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,032] Param max_depth unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,036] Param min_child_weight unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,039] Param subsample unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,044] Param colsample_bytree unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,047] Param learning_rate unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,049] Param max_depth unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,053] Param min_child_weight unique value length is less than 2.\n",
      "[W 2024-11-20 20:03:38,055] Param num_boost_round unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:12,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-10\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 182 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 182 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-10/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:12,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 20:03:40,843] Trial 1 finished with value: 0.6025204957749535 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'learning_rate': 0.9248621824944632, 'colsample_bytree': 0.6763324430409442, 'subsample': 0.8503748535517461, 'num_boost_round': 26}. Best is trial 0 with value: 0.5434750359790907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05<00:08,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-11\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 152 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 152 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-11/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08<00:08,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 20:03:43,882] Trial 2 finished with value: 0.7003023342224418 and parameters: {'max_depth': 9, 'min_child_weight': 2, 'learning_rate': 0.6093007177207064, 'colsample_bytree': 0.5624514367556817, 'subsample': 0.8398055160916891, 'num_boost_round': 36}. Best is trial 0 with value: 0.5434750359790907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08<00:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-12\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 142 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 142 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-12/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11<00:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 20:03:47,313] Trial 3 finished with value: 0.8321515612854721 and parameters: {'max_depth': 0, 'min_child_weight': 6, 'learning_rate': 0.5961060913531242, 'colsample_bytree': 0.5744904558534932, 'subsample': 0.9077398268536682, 'num_boost_round': 30}. Best is trial 0 with value: 0.5434750359790907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12<00:03,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-13\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 147 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 147 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-13/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:14<00:03,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 20:03:49,875] Trial 4 finished with value: 0.5908459876780345 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'learning_rate': 0.8451446057224135, 'colsample_bytree': 0.7004343247102691, 'subsample': 0.7012432746771452, 'num_boost_round': 37}. Best is trial 0 with value: 0.5434750359790907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.543475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:14<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=5,\n",
    "    show_progress_bar=True,\n",
    "    callbacks=[neptune_optuna_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxJPA0Rn_ffz"
   },
   "source": [
    "### Stop the study level run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gx5yy3Sk_ffz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/thefunktion/s4e11/e/KAGGLE-8/metadata\n"
     ]
    }
   ],
   "source": [
    "run_study_level.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArFt9hXv_ffz"
   },
   "source": [
    "## Compare the runs, and choose the best model to move to production\n",
    "\n",
    "You can compare, choose, and promote models both manually using the Neptune web app, or programmatically using the Neptune Python client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6bayzns_ffz"
   },
   "source": [
    "### Manually through the Neptune web app\n",
    "\n",
    "In this section, we'll:\n",
    "* Explore logged study and trial level metadata using [custom dashboards](https://docs.neptune.ai/app/custom_dashboard/)\n",
    "* Compare trials and sweeps using [custom table views](https://docs.neptune.ai/app/custom_views/)\n",
    "* Select the best model version and update its stage to *production*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0g0Ldmv_ff0"
   },
   "source": [
    "#### ðŸ” Explore the runs\n",
    "* Browse through the logged metadata, images, and charts in the study and trial-level runs.\n",
    "* To view all important metadata in one place, create custom dashboards.\n",
    "\n",
    "You can also browse these example custom dashboards:\n",
    "* [Example study-level custom dashboard](https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/details?viewId=9b71ae0c-8946-4a21-9f1a-4062cad659a4&detailsTab=dashboard&dashboardId=9b71b35b-13fe-4b7d-9d24-a0922d3b07d3&shortId=EET-34&type=run)\n",
    "* [Example trial-level custom dashboard](https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/details?viewId=9cb5bc7c-3bce-4c69-8f5c-90d3d9cc682c&detailsTab=dashboard&dashboardId=9cb5c2b5-d0ab-4760-8c96-2e3116db1089&shortId=EET-36&type=run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id8gKP7g_ff0"
   },
   "source": [
    "#### âš–ï¸ Compare models\n",
    "\n",
    "* To sort models, add important metrics to the **Experiments** table\n",
    "* Select models within or across studies for more granular comparison\n",
    "\n",
    "You can also browse an example custom table view with [models grouped by stage and sorted by score](https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/table?viewId=9cb5bc7c-3bce-4c69-8f5c-90d3d9cc682c) and custom dashboard [comparing models across stages](https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/compare?viewId=9cb5bc7c-3bce-4c69-8f5c-90d3d9cc682c&dash=dashboard&dashboardId=Compare-models-9cb5bf5a-32c9-4def-addc-0fb8bb1a9ce3&compare=EwTgNAjJ1cP3KTJA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEWGh1-v_ff0"
   },
   "source": [
    "#### ðŸ¥‡ Promote the best model to \"production\"\n",
    "\n",
    "* Browse through all the models\n",
    "* Update the stage of the best model to \"production\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyxU3-oe_ff0"
   },
   "source": [
    "### Select the best model programmatically\n",
    "\n",
    "All the comparisons and selections done manually above can also be automated programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gqMBs9m_ff0"
   },
   "source": [
    "#### Download the runs table as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h0DjBuez_ff0"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m score_namespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/early_stopping/best_score\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# This is where the best score is logged in Neptune\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mneptune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mread-only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/metadata_containers/project.py:161\u001b[0m, in \u001b[0;36mProject.__init__\u001b[0;34m(self, project, api_token, mode, flush_period, proxies, async_lag_callback, async_lag_threshold, async_no_progress_callback, async_no_progress_threshold)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m Mode\u001b[38;5;241m.\u001b[39mOFFLINE:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NeptuneException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be initialized in OFFLINE mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflush_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_lag_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_lag_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_lag_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_lag_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_no_progress_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_no_progress_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_no_progress_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_no_progress_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/metadata_containers/metadata_container.py:163\u001b[0m, in \u001b[0;36mMetadataContainer.__init__\u001b[0;34m(self, project, api_token, mode, flush_period, proxies, async_lag_callback, async_lag_threshold, async_no_progress_callback, async_no_progress_threshold)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend: NeptuneBackend \u001b[38;5;241m=\u001b[39m get_backend(mode\u001b[38;5;241m=\u001b[39mmode, api_token\u001b[38;5;241m=\u001b[39mapi_token, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_qualified_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m conform_optional(project, QualifiedName)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_api_object: Project \u001b[38;5;241m=\u001b[39m \u001b[43mproject_name_lookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_project_qualified_name\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_id: UniqueId \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_api_object\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_object: ApiExperiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_api_object()\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/internal/backends/project_name_lookup.py:46\u001b[0m, in \u001b[0;36mproject_name_lookup\u001b[0;34m(backend, name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     available_projects \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mget_available_projects()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NeptuneMissingProjectNameException(\n\u001b[1;32m     42\u001b[0m         available_workspaces\u001b[38;5;241m=\u001b[39mavailable_workspaces,\n\u001b[1;32m     43\u001b[0m         available_projects\u001b[38;5;241m=\u001b[39mavailable_projects,\n\u001b[1;32m     44\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/common/backends/utils.py:79\u001b[0m, in \u001b[0;36mwith_api_exceptions_handler.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidHeader \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Neptune-Api-Token\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/internal/backends/hosted_neptune_backend.py:225\u001b[0m, in \u001b[0;36mHostedNeptuneBackend.get_project\u001b[0;34m(self, project_id)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workspace:\n\u001b[1;32m    222\u001b[0m         available_projects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28mfilter\u001b[39m(\n\u001b[1;32m    224\u001b[0m                 \u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name,\n\u001b[0;32m--> 225\u001b[0m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_available_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_term\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m         )\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(available_projects) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    230\u001b[0m             project \u001b[38;5;241m=\u001b[39m available_projects[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/common/backends/utils.py:79\u001b[0m, in \u001b[0;36mwith_api_exceptions_handler.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidHeader \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Neptune-Api-Token\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/internal/backends/hosted_neptune_backend.py:276\u001b[0m, in \u001b[0;36mHostedNeptuneBackend.get_available_projects\u001b[0;34m(self, workspace_id, search_term)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;129m@with_api_exceptions_handler\u001b[39m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_available_projects\u001b[39m(\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m, workspace_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, search_term: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Project]:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistProjects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43morganizationIdentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43msearchTerm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_term\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43msortBy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlastViewed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43msortDirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescending\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43muserRelation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemberOrHigher\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mDEFAULT_REQUEST_KWARGS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresponse()\n\u001b[1;32m    285\u001b[0m         projects \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mentries\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    288\u001b[0m                 \u001b[38;5;28;01mlambda\u001b[39;00m project: Project(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m             )\n\u001b[1;32m    296\u001b[0m         )\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/neptune/internal/backends/swagger_client_wrapper.py:111\u001b[0m, in \u001b[0;36mApiMethodWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FinishedApiResponseFuture(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# wait synchronously\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_neptune_http_errors(e\u001b[38;5;241m.\u001b[39mresponse, exception\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/bravado/http_future.py:197\u001b[0m, in \u001b[0;36mHttpFuture.response\u001b[0;34m(self, timeout, fallback_result, exceptions_to_catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     exceptions_to_catch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(chain(exceptions_to_catch, (ForcedFallbackResultError,)))\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     incoming_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_incoming_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     request_end_time \u001b[38;5;241m=\u001b[39m monotonic\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    200\u001b[0m     swagger_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_swagger_result(incoming_response)\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/bravado/http_future.py:124\u001b[0m, in \u001b[0;36mreraise_errors.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m connection_errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mconnection_errors \u001b[38;5;129;01mor\u001b[39;00m ())\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m connection_errors \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39m_raise_connection_error(exception)\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/bravado/http_future.py:291\u001b[0m, in \u001b[0;36mHttpFuture._get_incoming_response\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;129m@reraise_errors\u001b[39m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_incoming_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# type: (typing.Optional[float]) -> IncomingResponse\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     inner_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     incoming_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_adapter(inner_response)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m incoming_response\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/bravado/requests_client.py:266\u001b[0m, in \u001b[0;36mRequestsFutureAdapter.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m prepared_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mprepare_request(request)\n\u001b[1;32m    259\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    260\u001b[0m     prepared_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    261\u001b[0m     proxies\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     cert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmisc_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssl_cert\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    265\u001b[0m )\n\u001b[0;32m--> 266\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepared_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmisc_options\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfollow_redirects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/workspaces/mlops/.venv/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/http/client.py:1419\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1419\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/ssl.py:1253\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1252\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_namespace = (\n",
    "    \"training/early_stopping/best_score\"  # This is where the best score is logged in Neptune\n",
    ")\n",
    "\n",
    "project = neptune.init_project(mode=\"read-only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zULe7SvG_ff0"
   },
   "source": [
    "Fetch the *champion* model. This is the model currently in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wMnNiQln_ff0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m champion_model_df \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241m.\u001b[39mfetch_runs_table(\n\u001b[1;32m      2\u001b[0m     query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`sys/group_tags`:stringSet CONTAINS \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduction\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[score_namespace],\n\u001b[1;32m      4\u001b[0m     sort_by\u001b[38;5;241m=\u001b[39mscore_namespace,\n\u001b[1;32m      5\u001b[0m     ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m      9\u001b[0m champion_model_df \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m champion_model_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo champion model found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'project' is not defined"
     ]
    }
   ],
   "source": [
    "champion_model_df = project.fetch_runs_table(\n",
    "    query='`sys/group_tags`:stringSet CONTAINS \"production\"',\n",
    "    columns=[score_namespace],\n",
    "    sort_by=score_namespace,\n",
    "    ascending=True,\n",
    "    limit=1,\n",
    ").to_pandas()\n",
    "\n",
    "champion_model_df if not champion_model_df.empty else print(\"No champion model found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1F_S05Q_ff0"
   },
   "source": [
    "Fetch the *challenger* model. This is the best model in *development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zahmCuH_ff0"
   },
   "outputs": [],
   "source": [
    "challenger_model_df = project.fetch_runs_table(\n",
    "    query='(`sys/group_tags`:stringSet CONTAINS \"development\") AND (`sys/tags`:stringSet CONTAINS \"trial-level\")',\n",
    "    columns=[score_namespace],\n",
    "    sort_by=score_namespace,\n",
    "    ascending=True,\n",
    "    limit=1,\n",
    ").to_pandas()\n",
    "\n",
    "challenger_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "samTf6VB_ff1"
   },
   "source": [
    "### Get scores and IDs of challenger and champion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PitpKqNp_ff1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    champion_model_id = champion_model_df[\"sys/id\"].values[0]\n",
    "    champion_model_score = champion_model_df[score_namespace].values[0]\n",
    "    print(f\"Champion model ID: {champion_model_id} and score: {champion_model_score}\")\n",
    "    NO_CHAMPION = False\n",
    "except KeyError:\n",
    "    print(\"âŒ No model found in production\")\n",
    "    NO_CHAMPION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFfpAxJ__ff1"
   },
   "outputs": [],
   "source": [
    "challenger_model_id = challenger_model_df[\"sys/id\"].values[0]\n",
    "challenger_model_score = challenger_model_df[score_namespace].values[0]\n",
    "print(f\"Challenger model ID: {challenger_model_id} and score: {challenger_model_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiUgEZYr_ff1"
   },
   "source": [
    "### Promote challenger to champion if score is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_-A8HCK_ff1"
   },
   "outputs": [],
   "source": [
    "if NO_CHAMPION:\n",
    "    print(f\"Promoting {challenger_model_id} to Production\")\n",
    "    with neptune.init_run(with_id=challenger_model_id) as challenger_model:\n",
    "        challenger_model[\"sys/group_tags\"].add(\"production\")\n",
    "        challenger_model[\"sys/group_tags\"].remove(\"development\")\n",
    "\n",
    "elif challenger_model_score < champion_model_score:\n",
    "    print(\"Challenger is better than champion\")\n",
    "\n",
    "    print(f\"Archiving champion model {champion_model_id}\")\n",
    "    with neptune.init_run(with_id=champion_model_id) as champion_model:\n",
    "        champion_model[\"sys/group_tags\"].remove(\"production\")\n",
    "        champion_model[\"sys/group_tags\"].add(\"archived\")\n",
    "\n",
    "    print(f\"Promoting {challenger_model_id} to Production\")\n",
    "    with neptune.init_run(with_id=challenger_model_id) as challenger_model:\n",
    "        challenger_model[\"sys/group_tags\"].add(\"production\")\n",
    "        challenger_model[\"sys/group_tags\"].remove(\"development\")\n",
    "\n",
    "else:\n",
    "    print(\"Champion model is better than challenger\")\n",
    "    print(f\"Archiving challenger model {challenger_model_id}\")\n",
    "    with neptune.init_run(with_id=challenger_model_id) as challenger_model:\n",
    "        challenger_model[\"sys/group_tags\"].add(\"archived\")\n",
    "        challenger_model[\"sys/group_tags\"].remove(\"development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyI22C2E_ff1"
   },
   "source": [
    "## Monitor model in production\n",
    "In this section, we'll:\n",
    "1. Download the model binary from the run to make predictions in production.\n",
    "2. Use [EvidentlyAI](https://www.evidentlyai.com/) to monitor the model in production.\n",
    "\n",
    "We'll use a modified version of a tutorial from the [Evidently documentation](https://docs.evidentlyai.com/get-started/tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELa7l8bz_ff5"
   },
   "source": [
    "### Setup\n",
    "\n",
    "We'll use an example dataset and mock historical predictions to use as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnIWDoki_ff6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import RegressionPreset\n",
    "from evidently.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfJuPW3f_ff6"
   },
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "housing_data = data.frame\n",
    "\n",
    "housing_data.rename(columns={\"MedHouseVal\": \"target\"}, inplace=True)\n",
    "\n",
    "reference = housing_data.sample(n=10000, replace=False)\n",
    "reference[\"prediction\"] = reference[\"target\"].values + np.random.normal(\n",
    "    0, 0.1, reference.shape[0]\n",
    ")  # Mocking historical predictions\n",
    "\n",
    "current = housing_data.sample(n=10000, replace=False)\n",
    "dcurrent = xgb.DMatrix(current.drop(\"target\", axis=1), label=current[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYrmrcOo_ff6"
   },
   "source": [
    "### Download saved model from Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wO4WfJo_ff6"
   },
   "outputs": [],
   "source": [
    "production_model_id = (\n",
    "    project.fetch_runs_table(\n",
    "        query='`sys/group_tags`:stringSet CONTAINS \"production\"',\n",
    "        columns=[],\n",
    "        sort_by=score_namespace,\n",
    "        ascending=True,\n",
    "        limit=1,\n",
    "    )\n",
    "    .to_pandas()[\"sys/id\"]\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "production_model = neptune.init_run(with_id=production_model_id)\n",
    "production_model[\"training/pickled_model\"].download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYPs43CT_ff6"
   },
   "source": [
    "### Make predictions from downloaded model on current test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caTYjwtH_ff6"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"pickled_model.pkl\", \"rb\") as f:\n",
    "    model = pkl.load(f)\n",
    "\n",
    "current[\"prediction\"] = model.predict(dcurrent)\n",
    "\n",
    "current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78v8yR3m_ff6"
   },
   "source": [
    "### Generate regression report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwuETvJ__ff6"
   },
   "outputs": [],
   "source": [
    "reg_performance_report = Report(metrics=[RegressionPreset()])\n",
    "\n",
    "reg_performance_report.run(reference_data=reference, current_data=current)\n",
    "\n",
    "reg_performance_report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2nIWWX-_ff6"
   },
   "source": [
    "### Upload report to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUPYRk9M_ff6"
   },
   "outputs": [],
   "source": [
    "reg_performance_report.save_html(\"report.html\")\n",
    "production_model[\"production/report\"].upload(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndZSWNWK_ff6"
   },
   "source": [
    "### Upload metrics to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqKr2nuT_ff7"
   },
   "outputs": [],
   "source": [
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "production_model[\"production/metrics\"] = stringify_unsupported(\n",
    "    reg_performance_report.as_dict()[\"metrics\"][0]\n",
    ")\n",
    "production_model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUJSXWsH_ff7"
   },
   "source": [
    "You can see an example of a production monitoring custom dashboard [here](https://app.neptune.ai/o/showcase/org/e2e-tracking/runs/details?viewId=9cb5bc7c-3bce-4c69-8f5c-90d3d9cc682c&detailsTab=dashboard&dashboardId=9cb5c04f-e405-497f-a028-d80d0a82c55a&shortId=EET-36&type=run&compare=EwTgNAjJ1cP3KTJA&lbViewUnpacked=true&sortBy=%5B%22training%2Fearly_stopping%2Fbest_score%22%5D&sortFieldType=%5B%22string%22%5D&sortFieldAggregationMode=%5B%22auto%22%5D&sortDirection=%5B%22ascending%22%5D&groupBy=%5B%22sys%2Fgroup_tags%22%5D&groupByFieldType=%5B%22stringSet%22%5D&groupByFieldAggregationMode=%5B%22auto%22%5D&suggestionsEnabled=false&query=((%60sys%2Ftags%60%3AstringSet%20CONTAINS%20%22trial-level%22)))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCW8dvOC_ff7"
   },
   "source": [
    "These metrics can then be fetched downstream to trigger a model refresh or retraining, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQRkKSdb_ff7"
   },
   "outputs": [],
   "source": [
    "retraining_threshold = 0.5  # example threshold\n",
    "\n",
    "if production_model[\"production/metrics/result/current/rmse\"].fetch() > retraining_threshold:\n",
    "    print(\"Model degradation detected. Retraining model...\")\n",
    "    ...\n",
    "else:\n",
    "    print(\"Model performance within expectations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crru0eA4_ff7"
   },
   "source": [
    "### (Optional) Maintain a history of production metrics\n",
    "\n",
    "The above method only logs the latest production metrics by overwriting the previous report and metrics.  \n",
    "To maintain a history of production metrics:\n",
    "\n",
    "* Log each report under a different folder, as shown below:\n",
    "\n",
    "  ```py\n",
    "  from datetime import datetime\n",
    "  npt_model[f\"production/{datetime.now().date()}/report\"].upload(\"report.html\")\n",
    "  ```\n",
    "  This will create a new folder for each day and upload the report to that folder.\n",
    "\n",
    "* [Log metrics as a series](https://docs.neptune.ai/logging/series/#numerical-series-floatseries), as shown below:\n",
    "\n",
    "  ```py\n",
    "  npt_model[\"production/rmse\"].append(rmse)\n",
    "  ```\n",
    "  This will let you visualize the production metrics over time as a chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clWWqql7_ff7"
   },
   "source": [
    "## Stop Neptune objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fX_HSkF_ff7"
   },
   "outputs": [],
   "source": [
    "project.stop()\n",
    "production_model.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Neptune_E2E_Model_Tracking.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
